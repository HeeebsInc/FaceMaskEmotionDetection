{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from PyFunctions import Viz\n",
    "from PyFunctions import Functions as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Value Count\n",
      "1    6000\n",
      "2    4965\n",
      "0    3995\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "TEST Value Count\n",
      "1    1774\n",
      "2    1233\n",
      "0     958\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "(14960, 224, 224, 3) (3965, 224, 224, 3)\n",
      "(14960, 3) (3965, 3)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mobilenet'\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = func.get_emotion_splits(dim = (224,224), model_type = model_name) \n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet(dim):\n",
    "    model = Sequential()\n",
    "#     optimizer = Adam(lr = .0005)\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "        input_tensor=Input(shape=dim))\n",
    "    \n",
    "    model.add(baseModel)\n",
    "    model.add(AveragePooling2D(pool_size=(7, 7)))\n",
    "    model.add(Flatten(name=\"flatten\"))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(3, activation=\"softmax\", name = 'Output'))\n",
    "\n",
    "    \n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramFiles\\conda\\envs\\FaceMaskEmotionDetection\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1266 of 2044 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1496/1496 [==============================] - 190s 127ms/step - loss: 1.0845 - acc: 0.4239 - val_loss: 1.0184 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01840, saving model to ModelWeights/Mobilenet_Emotions.h5\n",
      "Epoch 2/2000\n",
      "1096/1496 [====================>.........] - ETA: 38s - loss: 1.0390 - acc: 0.4563"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=8, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(f'ModelWeights/Mobilenet_Emotions.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 10\n",
    "    \n",
    "\n",
    "dim = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "mobilenet = get_mobilenet(dim =dim)\n",
    "\n",
    "    \n",
    "augmentation =ImageDataGenerator(rotation_range = 30, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "mobilenet_history = mobilenet.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(mobilenet_history, 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = [np.argmax(i) for i in mobilenet.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "y_train_prob = [np.argmax(i) for i in mobilenet.predict(x_train)]\n",
    "y_train_labels = [np.argmax(i) for i in y_train]\n",
    "train_cnf = confusion_matrix(y_train_labels, y_train_prob)\n",
    "\n",
    "#this function creates a confusion matrix given the confusion matrixes of test and train\n",
    "Viz.plot_model_cm(test_cnf, train_cnf, classes = ['No Mask', 'Mask'], theme = 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceMaskEmotionDetection",
   "language": "python",
   "name": "facemaskemotiondetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
