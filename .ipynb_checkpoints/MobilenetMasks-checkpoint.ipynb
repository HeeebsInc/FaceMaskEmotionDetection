{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 224, 224, 3) (992, 224, 224, 3)\n",
      "(10000, 2) (992, 2)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Mobilenet'\n",
    "def get_pickles(pick_name):\n",
    "    x_train, x_test, y_train, y_test, x_val, y_val = pickle.load(open(f'../Pickles/TTSMask_{pick_name}.p', 'rb'))\n",
    "    return x_train, x_test, y_train, y_test, x_val, y_val\n",
    "\n",
    "x_train, x_test, y_train, y_test, x_val, y_val  = get_pickles(model_name) \n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet(dim):\n",
    "    model = Sequential()\n",
    "    optimizer = Adam(lr = .0005)\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "        input_tensor=Input(shape=dim))\n",
    "    \n",
    "    model.add(baseModel)\n",
    "    model.add(AveragePooling2D(pool_size=(7, 7)))\n",
    "    model.add(Flatten(name=\"flatten\"))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(2, activation=\"sigmoid\", name = 'Output'))\n",
    "\n",
    "    \n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n",
      "F:\\ProgramFiles\\conda\\envs\\FaceMaskEmotionDetection\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "157/157 [==============================] - 136s 868ms/step - loss: 0.1836 - acc: 0.9280 - val_loss: 0.1767 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17666, saving model to ModelWeights/Mobilenet_Mobilenet.h5\n",
      "Epoch 2/2000\n",
      "157/157 [==============================] - 89s 568ms/step - loss: 0.0959 - acc: 0.9660 - val_loss: 0.2126 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17666\n",
      "Epoch 3/2000\n",
      "157/157 [==============================] - 94s 596ms/step - loss: 0.0867 - acc: 0.9668 - val_loss: 0.1138 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17666 to 0.11376, saving model to ModelWeights/Mobilenet_Mobilenet.h5\n",
      "Epoch 4/2000\n",
      "157/157 [==============================] - 93s 591ms/step - loss: 0.0684 - acc: 0.9762 - val_loss: 0.1497 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11376\n",
      "Epoch 5/2000\n",
      "157/157 [==============================] - 92s 588ms/step - loss: 0.0631 - acc: 0.9773 - val_loss: 0.1130 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11376 to 0.11304, saving model to ModelWeights/Mobilenet_Mobilenet.h5\n",
      "Epoch 6/2000\n",
      " 67/157 [===========>..................] - ETA: 49s - loss: 0.0696 - acc: 0.9747"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=5, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(f'ModelWeights/Mobilenet_{model_name}.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 64\n",
    "    \n",
    "\n",
    "dim = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "mobilenet = get_mobilenet(dim =dim)\n",
    "\n",
    "    \n",
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "augmentation.fit(x_train)\n",
    "mobilenet_history = mobilenet.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(mobilenet_history, 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = [np.argmax(i) for i in mobilenet.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "val_prob = [np.argmax(i) for i in mobilenet.predict(val_x)]\n",
    "val_labels = [np.argmax(i) for i in val_y]\n",
    "val_cnf = confusion_matrix(val_labels, val_prob)\n",
    "\n",
    "#this function creates a confusion matrix given the confusion matrixes of test and train\n",
    "Viz.plot_model_cm(test_cnf, val_cnf, classes = ['No Mask', 'Mask'], theme = 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceMaskEmotionDetection",
   "language": "python",
   "name": "facemaskemotiondetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
