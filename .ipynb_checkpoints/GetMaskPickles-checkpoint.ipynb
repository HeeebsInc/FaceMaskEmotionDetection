{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Images With Mask:  64%|███████████████████████████████████████████████████████████████████████████▋                                          | 1229/1915 [00:02<00:00, 709.73it/s]F:\\ProgramFiles\\conda\\envs\\FaceMaskEmotionDetection\\lib\\site-packages\\PIL\\Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Getting Images With Mask:  80%|█████████████████████████████████████████████████████████████████████████████████████████████▊                        | 1523/1915 [00:05<00:03, 122.22it/s]"
     ]
    }
   ],
   "source": [
    "#GITHUB\n",
    "def get_image_value(path, dim, bw): \n",
    "    '''This function will read an image and convert to a specified version and resize depending on which algorithm is being used.  If edge is specified as true, it will pass the img array to get_edged which returns a filtered version of the img'''\n",
    "    img = image.load_img(path, target_size = dim)\n",
    "    img = image.img_to_array(img)\n",
    "    if bw == True: \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.reshape(img.shape[0], img.shape[1],1)\n",
    "    return img/255\n",
    "\n",
    "\n",
    "def get_splits(dim, pick_name, bw = False): \n",
    "    \n",
    "    mask_paths = [f'../GithubData/with_mask/{i}' for i in os.listdir('../GithubData/with_mask')]\n",
    "    mask_labels = [1 for i in range(len(mask_paths))]\n",
    "    mask_images = [get_image_value(i, dim, bw) for i in tqdm(mask_paths, desc = 'Getting Images With Mask')]\n",
    "    \n",
    "    nomask_paths = [f'../GithubData/without_mask/{i}' for i in os.listdir('../GithubData/without_mask')]\n",
    "    nomask_labels = [0 for i in range(len(nomask_paths))]\n",
    "    nomask_images = [get_image_value(i, dim, bw) for i in tqdm(nomask_paths, desc = 'Getting Images With No Mask')]\n",
    "\n",
    "    image_list = np.array(nomask_images + mask_images)\n",
    "    labels = np.array(nomask_labels + mask_labels)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(image_list, labels, stratify = labels, random_state = 10, train_size = .8)\n",
    "    \n",
    "    print('Train Value Counts')\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test Value Counts')\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)    \n",
    "    \n",
    "    tts = (x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    pickle.dump(tts, open(f'../Pickles/TTS_{pick_name}.p', 'wb'), protocol = 4)\n",
    "    \n",
    "    return tts\n",
    "    \n",
    "\n",
    "dim = (250,250)\n",
    "return_dict = get_splits(dim, pick_name = 'GithubNormal', bw = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Train Images:   1%|█▌                                                                                                                       | 124/10000 [00:00<00:07, 1239.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Value Counts\n",
      "1    5000\n",
      "0    5000\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Train Images: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:12<00:00, 792.69it/s]\n",
      "Getting Test Images:   9%|███████████▎                                                                                                                  | 89/992 [00:00<00:01, 889.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Value Counts\n",
      "0    509\n",
      "1    483\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Test Images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 992/992 [00:01<00:00, 866.18it/s]\n",
      "Getting Validation Images:  12%|██████████████▌                                                                                                         | 97/800 [00:00<00:00, 969.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Value Counts\n",
      "1    400\n",
      "0    400\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Validation Images: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:00<00:00, 876.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling The Data\n"
     ]
    }
   ],
   "source": [
    "def get_image_value(path, dim, bw): \n",
    "    '''This function will read an image and convert to a specified version and resize depending on which algorithm is being used.  If edge is specified as true, it will pass the img array to get_edged which returns a filtered version of the img'''\n",
    "    img = image.load_img(path, target_size = dim)\n",
    "    img = image.img_to_array(img)\n",
    "    if bw == True: \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.reshape(img.shape[0], img.shape[1],1)\n",
    "    return img/255\n",
    "\n",
    "\n",
    "def get_splits(dim, pick_name, bw = False): \n",
    "    \n",
    "    #Train Set\n",
    "    train_mask_path = [f'../FaceMaskDataset/Train/WithMask/{i}' for i in os.listdir('../FaceMaskDataset/Train/WithMask')]\n",
    "    train_mask_label = [1 for i in range(len(train_mask_path))]\n",
    "    train_nomask_path = [f'../FaceMaskDataset/Train/WithoutMask/{i}' for i in os.listdir('../FaceMaskDataset/Train/WithoutMask')]\n",
    "    train_nomask_label = [0 for i in range(len(train_nomask_path))]\n",
    "\n",
    "    train_paths = train_mask_path + train_nomask_path \n",
    "    train_labels = np.array(train_mask_label + train_nomask_label) \n",
    "    \n",
    "    print('Train Value Counts')\n",
    "    print(pd.Series(train_labels).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    train_images = np.array([get_image_value(i, dim, bw) for i in tqdm(train_paths, desc = 'Getting Train Images')])\n",
    "    train_images, train_labels = sk_shuffle(train_images, train_labels)\n",
    "    train_dict = dict(images = train_images, labels = train_labels)\n",
    "    \n",
    "    #Test Set\n",
    "    test_mask_path = [f'../FaceMaskDataset/Test/WithMask/{i}' for i in os.listdir('../FaceMaskDataset/Test/WithMask')]\n",
    "    test_mask_label = [1 for i in range(len(test_mask_path))]\n",
    "    test_nomask_path = [f'../FaceMaskDataset/Test/WithoutMask/{i}' for i in os.listdir('../FaceMaskDataset/Test/WithoutMask')]\n",
    "    test_nomask_label = [0 for i in range(len(test_nomask_path))]\n",
    "\n",
    "    test_paths = test_mask_path + test_nomask_path\n",
    "    test_labels = np.array(test_mask_label + test_nomask_label) \n",
    "    print('Test Value Counts')\n",
    "    print(pd.Series(test_labels).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    test_labels = to_categorical(test_labels)\n",
    "    test_images = np.array([get_image_value(i, dim, bw) for i in tqdm(test_paths, desc = 'Getting Test Images')])\n",
    "    test_images, test_labels = sk_shuffle(test_images, test_labels)\n",
    "    test_dict = dict(images = test_images, labels = test_labels)\n",
    "    \n",
    "    #Validation Set\n",
    "    val_mask_path = [f'../FaceMaskDataset/Validation/WithMask/{i}' for i in os.listdir('../FaceMaskDataset/Validation/WithMask')]\n",
    "    val_mask_label = [1 for i in range(len(val_mask_path))]\n",
    "    val_nomask_path = [f'../FaceMaskDataset/Validation/WithoutMask/{i}' for i in os.listdir('../FaceMaskDataset/Validation/WithoutMask')]\n",
    "    val_nomask_label = [0 for i in range(len(val_nomask_path))]\n",
    "    \n",
    "    val_paths = val_mask_path + val_nomask_path \n",
    "    val_labels = np.array(val_mask_label + val_nomask_label)\n",
    "    print('Validation Value Counts')\n",
    "    print(pd.Series(val_labels).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    val_labels = to_categorical(val_labels)\n",
    "    val_images = np.array([get_image_value(i, dim, bw) for i in tqdm(val_paths, desc = 'Getting Validation Images')])\n",
    "    val_images, val_labels = sk_shuffle(val_images, val_labels)\n",
    "    val_dict = dict(images = val_images, labels = val_labels) \n",
    "    \n",
    "    return_dict = dict(train = train_dict, test = test_dict, validation = val_dict)\n",
    "    \n",
    "    print('Pickling The Data')\n",
    "    pickle.dump(return_dict, open(f'../Pickles/TTSDict_{pick_name}.p', 'wb'), protocol = 4)\n",
    "    \n",
    "    return return_dict\n",
    "    \n",
    "\n",
    "dim = (250,250)\n",
    "return_dict = get_splits(dim, pick_name = 'BW', bw = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250, 1)\n"
     ]
    }
   ],
   "source": [
    "test_img = return_dict['train']['images'][0]\n",
    "print(test_img.shape)\n",
    "cv2.imshow('Test', test_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceMaskEmotionDetection",
   "language": "python",
   "name": "facemaskemotiondetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
