{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from PyFunctions import Viz\n",
    "from PyFunctions import Functions as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Value Counts\n",
      "1    5000\n",
      "0    5000\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "TEST Value Counts\n",
      "0    509\n",
      "1    483\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "VALIDATION Value Counts\n",
      "1    400\n",
      "0    400\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "dim = (224,224)\n",
    "\n",
    "x_train, x_test, y_train, y_test, x_val, y_val = func.get_mask_splits(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet(dim):\n",
    "    model = Sequential()\n",
    "    optimizer = Adam(lr = .0005)\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "        input_tensor=Input(shape=dim))\n",
    "    \n",
    "    model.add(baseModel)\n",
    "    model.add(AveragePooling2D(pool_size=(7, 7)))\n",
    "    model.add(Flatten(name=\"flatten\"))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(2, activation=\"sigmoid\", name = 'Output'))\n",
    "\n",
    "    \n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n",
      "F:\\ProgramFiles\\conda\\envs\\FaceMaskEmotionDetection\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1398 of 2052 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 133s 848ms/step - loss: 0.1937 - acc: 0.9206 - val_loss: 0.3634 - val_acc: 0.8478\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36340, saving model to ModelWeights/Mobilenet_Masks.h5\n",
      "Epoch 2/2000\n",
      "157/157 [==============================] - 86s 550ms/step - loss: 0.0947 - acc: 0.9663 - val_loss: 0.3759 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36340\n",
      "Epoch 3/2000\n",
      "157/157 [==============================] - 90s 576ms/step - loss: 0.0832 - acc: 0.9703 - val_loss: 0.3132 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36340 to 0.31321, saving model to ModelWeights/Mobilenet_Masks.h5\n",
      "Epoch 4/2000\n",
      "157/157 [==============================] - 90s 574ms/step - loss: 0.0695 - acc: 0.9755 - val_loss: 0.1480 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31321 to 0.14802, saving model to ModelWeights/Mobilenet_Masks.h5\n",
      "Epoch 5/2000\n",
      "157/157 [==============================] - 90s 573ms/step - loss: 0.0650 - acc: 0.9771 - val_loss: 0.1396 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14802 to 0.13957, saving model to ModelWeights/Mobilenet_Masks.h5\n",
      "Epoch 6/2000\n",
      "157/157 [==============================] - 90s 573ms/step - loss: 0.0641 - acc: 0.9779 - val_loss: 0.2344 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13957\n",
      "Epoch 7/2000\n",
      "157/157 [==============================] - 93s 592ms/step - loss: 0.0622 - acc: 0.9785 - val_loss: 0.1219 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.13957 to 0.12195, saving model to ModelWeights/Mobilenet_Masks.h5\n",
      "Epoch 8/2000\n",
      "157/157 [==============================] - 91s 578ms/step - loss: 0.0565 - acc: 0.9798 - val_loss: 0.0544 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12195 to 0.05442, saving model to ModelWeights/Mobilenet_Masks.h5\n",
      "Epoch 9/2000\n",
      "157/157 [==============================] - 90s 574ms/step - loss: 0.0582 - acc: 0.9790 - val_loss: 0.0747 - val_acc: 0.9677\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05442\n",
      "Epoch 10/2000\n",
      "122/157 [======================>.......] - ETA: 19s - loss: 0.0573 - acc: 0.9805"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=5, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(f'ModelWeights/Mobilenet_Masks.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 64\n",
    "    \n",
    "\n",
    "dim = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "mobilenet = get_mobilenet(dim =dim)\n",
    "\n",
    "    \n",
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "augmentation.fit(x_train)\n",
    "mobilenet_history = mobilenet.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(mobilenet_history, 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_roc_auc(mobilenet, x_val, y_val, 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_cm(test_cm, train_cm, classes,\n",
    "                          theme, cmap=plt.cm.Blues, path = None, normalize=False):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    plt.style.use(theme)\n",
    "\n",
    "    if normalize:\n",
    "        test_cm = test_cm.astype('float') / test_cm.sum(axis=1)[:, np.newaxis]\n",
    "        train_cm = train_cm.astype('float') / train_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize = (8,8))\n",
    "    \n",
    "    #Test Set\n",
    "    ax[0].imshow(test_cm, interpolation='nearest', cmap=cmap)\n",
    "    ax[0].set_title('CM for Test')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax[0].set_xticks(tick_marks, classes)\n",
    "    ax[0].set_yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = test_cm.max() / 2.\n",
    "    for i, j in itertools.product(range(test_cm.shape[0]), range(test_cm.shape[1])):\n",
    "        ax[0].text(j, i, format(test_cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if test_cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax[0].set_ylabel('True label')\n",
    "    ax[0].set_xlabel('Predicted label')\n",
    "    ax[0].set_ylim(2.5, -.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Train Set\n",
    "    ax[1].imshow(train_cm, interpolation='nearest', cmap=cmap)\n",
    "    ax[1].set_title('CM for Train')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax[1].set_xticks(tick_marks, classes)\n",
    "    ax[1].set_yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = train_cm.max() / 2.\n",
    "    for i, j in itertools.product(range(train_cm.shape[0]), range(train_cm.shape[1])):\n",
    "        ax[1].text(j, i, format(train_cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if train_cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax[1].set_ylabel('True label')\n",
    "    ax[1].set_xlabel('Predicted label')\n",
    "    ax[1].set_ylim(2.5, -.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if path: \n",
    "        plt.savefig(path)\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = [np.argmax(i) for i in mobilenet.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "val_prob = [np.argmax(i) for i in mobilenet.predict(x_val)]\n",
    "val_labels = [np.argmax(i) for i in y_val]\n",
    "val_cnf = confusion_matrix(val_labels, val_prob)\n",
    "\n",
    "#this function creates a confusion matrix given the confusion matrixes of test and train\n",
    "Viz.plot_model_cm(test_cnf, val_cnf, classes = ['No Mask', 'Mask'], theme = 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceMaskEmotionDetection",
   "language": "python",
   "name": "facemaskemotiondetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
