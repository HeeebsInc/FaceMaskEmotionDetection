{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'BW'\n",
    "def get_pickles(name):\n",
    "    combined_dict = pickle.load(open(f'../Pickles/TTSDict_{name}.p', 'rb'))\n",
    "    \n",
    "    x_train = combined_dict['train']['images']\n",
    "    x_test = combined_dict['test']['images']\n",
    "    \n",
    "    y_train = combined_dict['train']['labels']\n",
    "    y_test = combined_dict['test']['labels']\n",
    "    \n",
    "    validation = combined_dict['validation']\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, validation \n",
    "\n",
    "x_train, x_test, y_train, y_test, validation  = get_pickles(model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 250, 250, 1) (992, 250, 250, 1)\n",
      "(10000, 2) (992, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(dim):\n",
    "    '''This function will create and compile a CNN given the input dimension'''\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)\n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Dense(2, activation='sigmoid', name = 'Output_Layer'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 91 of 395 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 95s 952ms/step - loss: 10.8294 - acc: 0.6217 - val_loss: 9.6891 - val_acc: 0.7828\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.68915, saving model to ModelWeights/CONV_BW.h5\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 81s 810ms/step - loss: 8.8386 - acc: 0.7194 - val_loss: 7.8624 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00002: val_loss improved from 9.68915 to 7.86243, saving model to ModelWeights/CONV_BW.h5\n",
      "Epoch 3/2000\n",
      " 84/100 [========================>.....] - ETA: 12s - loss: 7.3014 - acc: 0.7414"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(f'ModelWeights/CONV_{model_name}.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 100\n",
    "    \n",
    "\n",
    "dim = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "normal_model = get_conv_model(dim =dim)\n",
    "\n",
    "# normal_model.load_weights('ModelWeights/Normal1.h5') \n",
    "\n",
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "augmentation.fit(x_train)\n",
    "normal_history = normal_model.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(normal_history, 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = [np.argmax(i) for i in normal_model.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "y_train_prob = [np.argmax(i) for i in normal_model.predict(x_train)]\n",
    "y_train_labels = [np.argmax(i) for i in y_train]\n",
    "train_cnf = confusion_matrix(y_train_labels, y_train_prob)\n",
    "\n",
    "#this function creates a confusion matrix given the confusion matrixes of test and train\n",
    "Viz.plot_model_cm(test_cnf, train_cnf, classes = ['No Mask', 'Mask'], theme = 'dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet(dim):\n",
    "    model = Sequential()\n",
    "    optimizer = Adam(lr = .0005)\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "        input_tensor=Input(shape=dim))\n",
    "    \n",
    "    model.add(baseModel)\n",
    "    model.add(AveragePooling2D(pool_size=(7, 7)))\n",
    "    model.add(Flatten(name=\"flatten\"))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2, activation=\"sigmoid\", name = 'Output'))\n",
    "\n",
    "    \n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramFiles\\conda\\envs\\FaceMaskEmotionDetection\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1808 of 2052 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 152s 485ms/step - loss: 0.1475 - acc: 0.9404 - val_loss: 0.1884 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18840, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 2/2000\n",
      "313/313 [==============================] - 112s 356ms/step - loss: 0.0911 - acc: 0.9667 - val_loss: 0.1224 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18840 to 0.12244, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 3/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0757 - acc: 0.9719 - val_loss: 0.1347 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12244\n",
      "Epoch 4/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0882 - acc: 0.9674 - val_loss: 0.0512 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12244 to 0.05116, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 5/2000\n",
      "313/313 [==============================] - 116s 369ms/step - loss: 0.0614 - acc: 0.9783 - val_loss: 0.0528 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05116\n",
      "Epoch 6/2000\n",
      "313/313 [==============================] - 118s 377ms/step - loss: 0.0659 - acc: 0.9756 - val_loss: 0.0783 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05116\n",
      "Epoch 7/2000\n",
      "313/313 [==============================] - 115s 367ms/step - loss: 0.0674 - acc: 0.9746 - val_loss: 0.1325 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05116\n",
      "Epoch 8/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0583 - acc: 0.9793 - val_loss: 0.0521 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05116\n",
      "Epoch 9/2000\n",
      "313/313 [==============================] - 114s 363ms/step - loss: 0.0747 - acc: 0.9715 - val_loss: 0.0400 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05116 to 0.04003, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 10/2000\n",
      "313/313 [==============================] - 112s 359ms/step - loss: 0.0562 - acc: 0.9797 - val_loss: 0.1175 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04003\n",
      "Epoch 11/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0563 - acc: 0.9790 - val_loss: 0.0603 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04003\n",
      "Epoch 12/2000\n",
      "313/313 [==============================] - 113s 360ms/step - loss: 0.0536 - acc: 0.9798 - val_loss: 0.1147 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04003\n",
      "Epoch 13/2000\n",
      "313/313 [==============================] - 113s 360ms/step - loss: 0.0600 - acc: 0.9782 - val_loss: 0.0579 - val_acc: 0.9723\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04003\n",
      "Epoch 14/2000\n",
      "313/313 [==============================] - 114s 363ms/step - loss: 0.0451 - acc: 0.9836 - val_loss: 0.1079 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04003\n",
      "Epoch 15/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0435 - acc: 0.9833 - val_loss: 0.0537 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04003\n",
      "Epoch 16/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0444 - acc: 0.9846 - val_loss: 0.0482 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04003\n",
      "Epoch 17/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0429 - acc: 0.9847 - val_loss: 0.0926 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04003\n",
      "Epoch 18/2000\n",
      "313/313 [==============================] - 113s 360ms/step - loss: 0.0408 - acc: 0.9853 - val_loss: 0.0824 - val_acc: 0.9592\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04003\n",
      "Epoch 19/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0388 - acc: 0.9862 - val_loss: 0.0609 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04003\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights/Mobilenet1.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 32\n",
    "    \n",
    "\n",
    "dim = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "mobilenet = get_mobilenet(dim =dim)\n",
    "\n",
    "    \n",
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "augmentation.fit(x_train)\n",
    "mobilenet_history = mobilenet.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceMaskEmotionDetection",
   "language": "python",
   "name": "facemaskemotiondetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
