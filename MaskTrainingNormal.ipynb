{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickles():\n",
    "    combined_dict = pickle.load(open('../Pickles/TTSDict.p', 'rb'))\n",
    "    \n",
    "    x_train = combined_dict['train']['images']\n",
    "    x_test = combined_dict['test']['images']\n",
    "    \n",
    "    y_train = combined_dict['train']['labels']\n",
    "    y_test = combined_dict['test']['labels']\n",
    "    \n",
    "    validation = combined_dict['validation']\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, validation \n",
    "\n",
    "x_train, x_test, y_train, y_test, validation  = get_pickles() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 250, 250, 3) (992, 250, 250, 3)\n",
      "(10000, 2) (992, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(dim):\n",
    "    '''This function will create and compile a CNN given the input dimension'''\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)\n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Dense(2, activation='sigmoid', name = 'Output_Layer'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 91 of 395 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 123s 1s/step - loss: 0.3490 - acc: 0.9719 - val_loss: 0.3235 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32348, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 110s 1s/step - loss: 0.3502 - acc: 0.9705 - val_loss: 0.3277 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32348\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 110s 1s/step - loss: 0.3413 - acc: 0.9735 - val_loss: 0.3117 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32348 to 0.31169, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.3354 - acc: 0.9742 - val_loss: 0.3191 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31169\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.3348 - acc: 0.9730 - val_loss: 0.3022 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.31169 to 0.30220, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.3291 - acc: 0.9760 - val_loss: 0.3182 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30220\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 113s 1s/step - loss: 0.3267 - acc: 0.9734 - val_loss: 0.3077 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30220\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3229 - acc: 0.9740 - val_loss: 0.3225 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.30220\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.3175 - acc: 0.9767 - val_loss: 0.2935 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30220 to 0.29347, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.3201 - acc: 0.9731 - val_loss: 0.2938 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.29347\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3154 - acc: 0.9754 - val_loss: 0.2947 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.29347\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3141 - acc: 0.9751 - val_loss: 0.2907 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.29347 to 0.29066, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3108 - acc: 0.9736 - val_loss: 0.2801 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29066 to 0.28015, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3042 - acc: 0.9766 - val_loss: 0.2814 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28015\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3039 - acc: 0.9761 - val_loss: 0.2815 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28015\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3078 - acc: 0.9723 - val_loss: 0.2961 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.28015\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3042 - acc: 0.9751 - val_loss: 0.2854 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.28015\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.3051 - acc: 0.9728 - val_loss: 0.2834 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.28015\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2941 - acc: 0.9749 - val_loss: 0.2680 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.28015 to 0.26799, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.2877 - acc: 0.9777 - val_loss: 0.2666 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.26799 to 0.26655, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2932 - acc: 0.9741 - val_loss: 0.2676 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.26655\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2850 - acc: 0.9794 - val_loss: 0.2675 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.26655\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2834 - acc: 0.9797 - val_loss: 0.2744 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.26655\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2906 - acc: 0.9774 - val_loss: 0.2691 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.26655\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.2847 - acc: 0.9785 - val_loss: 0.2704 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26655\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2846 - acc: 0.9795 - val_loss: 0.2672 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.26655\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 113s 1s/step - loss: 0.2837 - acc: 0.9783 - val_loss: 0.2666 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.26655\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2850 - acc: 0.9783 - val_loss: 0.2662 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.26655 to 0.26625, saving model to ModelWeights/Normal1.h5\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2877 - acc: 0.9788 - val_loss: 0.2666 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26625\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2857 - acc: 0.9794 - val_loss: 0.2663 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.26625\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights/Normal1.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 100\n",
    "    \n",
    "\n",
    "dim = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "normal_model = get_conv_model(dim =dim)\n",
    "normal_model.load_weights('ModelWeights/Normal1.h5') \n",
    "\n",
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "augmentation.fit(x_train)\n",
    "normal_history = normal_model.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet(dim):\n",
    "    model = Sequential()\n",
    "    optimizer = Adam(lr = .0005)\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "        input_tensor=Input(shape=dim))\n",
    "    \n",
    "    model.add(baseModel)\n",
    "    model.add(AveragePooling2D(pool_size=(7, 7)))\n",
    "    model.add(Flatten(name=\"flatten\"))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2, activation=\"sigmoid\", name = 'Output'))\n",
    "\n",
    "    \n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramFiles\\conda\\envs\\FaceMaskEmotionDetection\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 1808 of 2052 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 152s 485ms/step - loss: 0.1475 - acc: 0.9404 - val_loss: 0.1884 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18840, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 2/2000\n",
      "313/313 [==============================] - 112s 356ms/step - loss: 0.0911 - acc: 0.9667 - val_loss: 0.1224 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18840 to 0.12244, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 3/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0757 - acc: 0.9719 - val_loss: 0.1347 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.12244\n",
      "Epoch 4/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0882 - acc: 0.9674 - val_loss: 0.0512 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12244 to 0.05116, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 5/2000\n",
      "313/313 [==============================] - 116s 369ms/step - loss: 0.0614 - acc: 0.9783 - val_loss: 0.0528 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05116\n",
      "Epoch 6/2000\n",
      "313/313 [==============================] - 118s 377ms/step - loss: 0.0659 - acc: 0.9756 - val_loss: 0.0783 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05116\n",
      "Epoch 7/2000\n",
      "313/313 [==============================] - 115s 367ms/step - loss: 0.0674 - acc: 0.9746 - val_loss: 0.1325 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05116\n",
      "Epoch 8/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0583 - acc: 0.9793 - val_loss: 0.0521 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05116\n",
      "Epoch 9/2000\n",
      "313/313 [==============================] - 114s 363ms/step - loss: 0.0747 - acc: 0.9715 - val_loss: 0.0400 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05116 to 0.04003, saving model to ModelWeights/Mobilenet1.h5\n",
      "Epoch 10/2000\n",
      "313/313 [==============================] - 112s 359ms/step - loss: 0.0562 - acc: 0.9797 - val_loss: 0.1175 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04003\n",
      "Epoch 11/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0563 - acc: 0.9790 - val_loss: 0.0603 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04003\n",
      "Epoch 12/2000\n",
      "313/313 [==============================] - 113s 360ms/step - loss: 0.0536 - acc: 0.9798 - val_loss: 0.1147 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04003\n",
      "Epoch 13/2000\n",
      "313/313 [==============================] - 113s 360ms/step - loss: 0.0600 - acc: 0.9782 - val_loss: 0.0579 - val_acc: 0.9723\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04003\n",
      "Epoch 14/2000\n",
      "313/313 [==============================] - 114s 363ms/step - loss: 0.0451 - acc: 0.9836 - val_loss: 0.1079 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04003\n",
      "Epoch 15/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0435 - acc: 0.9833 - val_loss: 0.0537 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04003\n",
      "Epoch 16/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0444 - acc: 0.9846 - val_loss: 0.0482 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04003\n",
      "Epoch 17/2000\n",
      "313/313 [==============================] - 113s 361ms/step - loss: 0.0429 - acc: 0.9847 - val_loss: 0.0926 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04003\n",
      "Epoch 18/2000\n",
      "313/313 [==============================] - 113s 360ms/step - loss: 0.0408 - acc: 0.9853 - val_loss: 0.0824 - val_acc: 0.9592\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04003\n",
      "Epoch 19/2000\n",
      "313/313 [==============================] - 113s 362ms/step - loss: 0.0388 - acc: 0.9862 - val_loss: 0.0609 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04003\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights/Mobilenet1.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 32\n",
    "    \n",
    "\n",
    "dim = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "mobilenet = get_mobilenet(dim =dim)\n",
    "\n",
    "    \n",
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "augmentation.fit(x_train)\n",
    "mobilenet_history = mobilenet.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceMaskEmotionDetection",
   "language": "python",
   "name": "facemaskemotiondetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
